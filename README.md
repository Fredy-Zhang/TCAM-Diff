# TCAM-Diff: Triplane-Aware Cross-Attention Medical Diffusion Model

[![AAAI 2025](https://img.shields.io/badge/AAAI-2025-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/34433)
[![DOI](https://img.shields.io/badge/DOI-10.1609%2Faaai.v39i21.34433-blue)](https://doi.org/10.1609/aaai.v39i21.34433)

Official implementation of **TCAM-Diff**, a novel 3D medical image generation model presented at [AAAI 2025](https://ojs.aaai.org/index.php/AAAI/article/view/34433).

## Paper

**[TCAM-Diff: Triplane-Aware Cross-Attention Medical Diffusion Model](https://ojs.aaai.org/index.php/AAAI/article/view/34433)**  
Zhenkai Zhang, Krista A. Ehinger, Tom Drummond  
*The University of Melbourne*  
*Proceedings of the AAAI Conference on Artificial Intelligence, 39(21), 22732â€“22740 (2025)*

<p align="center">
  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/34433/36588">ðŸ“„ Paper (PDF)</a>
  &nbsp;&nbsp;|&nbsp;&nbsp;
  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/34433/40118">ðŸ“„ Poster</a>
</p>

---

## Abstract

We introduce TCAM-Diff, a novel 3D medical image generation model that reduces the memory requirements to encode and generate high-resolution 3D data. This model utilizes a decoder-only autoencoder method to learn triplane representation from dense volume and leverages generalization operations to prevent overfitting. Subsequently, it uses a triplane-aware cross-attention diffusion model to learn and integrate these features effectively. Furthermore, the features generated by the diffusion model can be rapidly transformed into 3D volumes using a pre-trained decoder module. Our experiments on three different scales of medical datasetsâ€”**BrainTumour** (128Ã—128Ã—128), **Pancreas** (256Ã—256Ã—256), and **Colon** (512Ã—512Ã—512)â€”demonstrated outstanding results. We utilized MSE and SSIM to evaluate reconstruction quality and leveraged the Wasserstein Generative Adversarial Network (W-GAN) critic to assess generative quality. Comparisons to existing approaches show that our method gives better reconstruction and generation results than other encoder-decoder methods with similar-sized latent spaces.

---

## Method Overview

- **Triplane representation**: Decoder-only autoencoder for memory-efficient encoding of 3D volumes
- **Generalization operations**: Mitigate overfitting on medical data
- **Triplane-aware cross-attention diffusion**: Effectively learns and integrates triplane features
- **Fast 3D decoding**: Pre-trained decoder converts diffusion outputs to 3D volumes

---

## Datasets

| Dataset | Resolution | Description |
|---------|------------|-------------|
| BrainTumour | 128Ã—128Ã—128 | Brain tumour imaging |
| Pancreas | 256Ã—256Ã—256 | Pancreas CT scans |
| Colon | 512Ã—512Ã—512 | Colon imaging |

---

## Installation

*(To be added with code release)*

```bash
# Coming soon
```

---

## Usage

*(To be added with code release)*

### Training

### Inference / Generation

---

## Acknowledgments

We thank The University of Melbourne for supporting this research. This work was presented at AAAI Technical Track on Machine Learning VII (AAAI-25).

---

## License

This project is licensed under the Apache License 2.0 â€” see the [LICENSE](LICENSE) file for details.

---

## Citation

If you use this code or find our work useful, please cite:

```bibtex
@inproceedings{zhang2025tcamdiff,
  title={TCAM-Diff: Triplane-Aware Cross-Attention Medical Diffusion Model},
  author={Zhang, Zhenkai and Ehinger, Krista A. and Drummond, Tom},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={21},
  pages={22732--22740},
  year={2025}
}
```
